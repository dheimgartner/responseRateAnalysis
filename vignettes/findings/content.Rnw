% !Rnw root = ../findings.Rnw

<<include=FALSE>>=
knitr::opts_knit$set(self.contained=FALSE)
@

%%%%%%%%%%%%%%%%%%%%
% ABSTRACT
%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
We investigate the relation between a survey's response burden and response rate, differentiating recruitment efforts and incentives paid. The results indicate that the effect of response burden is more negative than previously expected. Recruitment shifts the response curve upwards, while incentives flatten it. Surveys beyond 2`000 points appear overly burdensome, sustaining high response rates only through recruitment coupled with incentives. Without incentives, the level effect of recruitment quickly vanishes. Contrary to previous findings, we can not identify a negative time-trend. The data, functions and workflow underlying this analysis are organized as an \rlan-package to foster a collective effort towards understanding response rates.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%
% KEYWORDS
%%%%%%%%%%%%%%%%%%%%
\textit{Keywords:} predicting, measurement, rating, survey instruments, response burden, response rate


%%%%%%%%%%%%%%%%%%%%
% QUESTIONS
%%%%%%%%%%%%%%%%%%%%
\section{Questions}

Counting \textit{response burden scores} \citep{schmid2019predicting} is not a very popular task at the Institute for Transport Planning and Systems (IVT, ETH Zurich). One or the other former PhD student got away without reporting them. However, the collective effort over the years yielded a unique dataset allowing us to understand response rates as a function of recruitment efforts and incentives. Other research institutes might therefore be encouraged to also contribute. This paper briefly elaborates the methodology once again and introduces the \responseRateAnalysis~\rlan-package (\url{https://github.com/dheimgartner/responseRateAnalysis}) with its helper functions to easily replicate the results. Since the last update \citep{axhausen2019predicting} a handful students left not until the final response burden score of their surveys was counted. Thanks to them, we feel that the time is right to update response rates results once again.

The main purpose of this paper is to replicate the analysis, update the estimates based on the enlarged sample and to make the analysis easily replicable: The \rlan-package can be installed as explained below but we hope that other research groups rather clone the repository and contribute with their scored survey instruments according to the guidelines outlined on github so that we or they can predict response rates from time to time again.

<<eval=FALSE>>=
devtools::install_github("dheimgartner/responseRateAnalyis")
@

%%%%%%%%%%%%%%%%%%%%
% METHODS
%%%%%%%%%%%%%%%%%%%%
\section{Methods}

The main data collection effort consists of scoring the survey instruments according to \cref{tab:response_burden_scheme}.

<<echo=FALSE>>=
tex <-
  response_burden_scheme %>%
  mutate(Item = stringr::str_replace_all(Item, "    ", "\\\\hspace{2em}")) %>%
  kableExtra::kbl(format = "latex",
                  caption = "Response burden: Points by question type and action",
                  label = "response_burden_scheme",
                  booktabs = TRUE,
                  escape = FALSE) %>%
  kableExtra::footnote(general = "Based on \\\\textit{Gesellschaft für Sozialforschung (GfS)}, Zürich, 2006 (updated).",
                       escape = FALSE,
                       footnote_as_chunk = TRUE,
                       general_title = "")
@

<<echo=FALSE, results='asis'>>=
tex
@

In comparison to the previous publication \citep{schmid2019predicting}, 14 additional surveys were added by IVT members. A new category (no recruitment but with incentive payments) can now be distinguished. However, only five studies fall in this category. The current state of the database is attached to the package \code{response\_rates} and its variables documented (\code{?response\_rates}). The full sample underlying this report can be found in \cref{tab:full_sample}.

The distribution of the response burden scores (RBS) for the four recruitment (R) and incentive (I) categories are visualized in \cref{fig:response_burden_scores}. The following abbreviations are used throughout the text: For example, \textit{RxI} stands for the category where respondents were recruited as well as incentives paid. An \textit{N} negates and hence as an example \textit{NRxNI} reflects the category without recruitment and incentives. The median RBS is 399 and surveys with a score higher than 1`500 are rare (twelve points roughly correspond to a one-minute response time).

\begin{figure}
<<response burden score, echo=FALSE, fig.width=3.75, fig.height=3.9, out.width='50%'>>=
rr <-
  response_rates %>%
  select(response_burden_score, response_rate, all_of(cat_cols)) %>%
  pivot_longer(all_of(cat_cols)) %>%
  filter(value == 1) %>%
  mutate(name = factor(name, levels = cat_cols))

group_counts <- paste0("N=", count(rr, name)[["n"]])

par(mgp = c(2, 1, 0))
boxplot(response_burden_score ~ name, data = rr,
        xlab = "Recruitment, incentive", ylab = "Response burden score",
        cex.lab = 0.7, cex.axis = 0.7)
mtext(group_counts, side = 3, at = 1:4, cex = 0.7)
@
\caption{Distribution of the response burden scores for \textit{recruitment x intentive} categories. \textit{RxI} stands for recruited, with incentives, \textit{N} negates.}
\label{fig:response_burden_scores}
\end{figure}

Building on \citet{axhausen2019predicting}, we estimate a logistic regression model relating response burden scores to log-transformed response rates:

\begin{equation}
\log \left( \frac{y_i}{100 - y_i} \right) = \beta_0 + \beta_1 \frac{x_i}{1000} + \varepsilon_i
\label{eq:response_burden}
\end{equation}

where $y_i$ denotes the response rate (in percent), $x_i$ represents the ex-ante response burden score, and $\varepsilon_i$ is a normally distributed clustered error term (similar errors for different survey waves of the same study). Observations were weighted by the square root of the sample size. The model was estimated for the entire sample (excluding surveys with a sample size less than ten) as well as separately for recruitment by incentive category. The exponential $\exp(\beta_1)$ represents a marginal change in the odds ratio (i.e., participation vs. non-participation).

If a survey instrument's response burden score increases by 100 points, the odds of participating decrease according to:

\begin{equation}
\left( \exp \left( \frac{\beta_1}{1000} \right) -1 \right) \cdot 100
\label{eq:log_odds_decrease}
\end{equation}

The basic workflow is as follows:

\begin{enumerate}
\item \code{default\_data()} loads and prepares the \code{response\_rates} data for estimation. It selects the input variables, computes the weights (\code{sqrt(sample\_size)}), rescales the response burden score (\code{response\_burden\_score / 1000}) and log transforms the response rate (\code{log(response\_rate / (100 - response\_rate))}).
\item Fit a linear regression model with \code{lm()}.
\item Add clustered standard errors with \code{add\_clustered()} which uses the \pkg{clubSandwich} \citep{clubsandwich} and \pkg{lmtest} package \citep{lmtest} under the hood to correct standard errors and related statistics.
\item The functions from the \pkg{texreg} \citep{texreg} package (e.g., \code{screenreg()} or \code{texreg()}) work together with the class \code{"clustered" "lm"} (as returned by \code{add\_clustered()}) and produce regression tables (such as the ones reported here).
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%
% FINDINGS
%%%%%%%%%%%%%%%%%%%%
\section{Findings}

The following code conducts the analysis for the full sample (i.e., same slope but different intercepts for the \textit{recruitment x incentive} categories):

<<>>=
dat <- default_data() %>%
  filter(sample_size >= 10)  # to be consistent with previous publications
fit <- lm(y ~ 0 + x + RxI + RxNI + NRxI + NRxNI,
          data = dat, weights = weight)
m1 <- add_clustered(fit, cluster = dat$survey_id, type = "CR2")
class(m1)
@

We repeat the above estimation for different samples, comparing the estimates of the last publication to the updated ones as well as estimate separate models for the four different recruitment and incentive categories. \cref{tab:comparison} summarises the results.

<<echo=FALSE>>=
estimator <- function(dat, subset) {
  dat_ <- subset(dat, subset = subset)
  fit <- lm(formula = y ~ x,
            data = dat_, weights = weight)
  m <- add_clustered(fit, cluster = dat_$survey_id, type = "CR2")
  m
}

m2 <- estimator(dat, subset = (dat$RxI == 1))
m3 <- estimator(dat, subset = (dat$RxNI == 1))
m4 <- estimator(dat, subset = (dat$NRxI == 1))
m5 <- estimator(dat, subset = (dat$NRxNI == 1))

dat_last <- subset(dat[1:67, ], sample_size >= 10)
fit <- lm(y ~ 0 + x + RxI + RxNI + NRxI + NRxNI,
          data = dat_last, weights = weight)
m1_last <- add_clustered(fit, cluster = dat_last$survey_id, type = "CR2")
m2_last <- estimator(dat_last, subset = (dat_last$RxI == 1))
m3_last <- estimator(dat_last, subset = (dat_last$RxNI == 1))
# m4_last <- estimator(dat_last, subset = (dat_last$NRxI == 1))  # not available
m5_last <- estimator(dat_last, subset = (dat_last$NRxNI ==  1))

m_last <- list(Pooled = m1_last,
               `RxI` = m2_last,
               `RxNI`= m3_last,
               `NRxNI` = m5_last)

## rename coefficients for table output
rename_coefs <- function(m_list) {
  m_list_ <-
    map(m_list, function(x) {
      if (length(x$coefficients) == 2) {
        names(x$coefficients) <- c("Intercept", "Response burden")
      } else {
        names(x$coefficients)[1] <- "Response burden"
      }
      x
    })
  return(m_list_)
}

m_last <- rename_coefs(m_last)

m <- list(Pooled = m1,
          `RxI` = m2,
          `RxNI` = m3,
          `NRxI` = m4,
          `NRxNI` = m5)

m <- rename_coefs(m)

## combine in one table
tmp <- m_last
m_both <- append(m, tmp)

tex <- texreg::texreg(m_both,
                      booktabs = TRUE,
                      use.packages = FALSE,
                      caption.above = TRUE,
                      custom.header = list("Updated models" = 1:5, "Old models\\dag" = 6:9),
                      caption = "Logistic regression results: Regressing response burden score on (logit-transformed) response rates",
                      label = "tab:comparison",
                      custom.note = "%stars. \\dag Based on the sample of the last publication. \\textit{RxI} = Recruited, with incentives, \\textit{N} negates.",
                      scalebox = 0.75,
                      float.pos = "h!")
@

<<echo=FALSE, results='asis'>>=
tex
@

For the newly added group (no recruitment but with incentive payments, \textit{NRxI}) the effect of the response burden is not significant, as expected because of limited sample size. Due to the logistic transformation, parameters reflect changes in log-odds when the RBS marginally increases. The effect of response burden is generally more negative than previously expected. The strongest effect can be found for the recruited subsample without incentive payment (\textit{RxNI}), where the odds of participating decrease by -0.297 (i.e., roughly 30\%) according to \cref{eq:log_odds_decrease} if the RBS increases by 100 points. The other comparisons are listed in \cref{tab:pc_odds}.

<<echo=FALSE>>=
f <- function(b) {
  (exp(b/1000) - 1) * 100
}

pc_odds <- function(m) {
  m %>%
    map(function(x) {
      b <- coef(x)[["Response burden"]]
      100 * f(b)
    })
}

pc <- pc_odds(m) %>%
  as.data.frame() %>%
  pivot_longer(everything())

pc_last <- pc_odds(m_last) %>%
  as.data.frame() %>%
  pivot_longer(everything())

pc_both <- left_join(pc, pc_last, by = "name") %>%
  mutate(name = stringr::str_replace_all(name, "\\.\\.", ", ")) %>%
  rename(Category = name, `Updated models [%]` = value.x, `Old models [%]` = value.y)

tex <-
  pc_both %>%
  kbl(format = "latex", digits = 2, booktabs = TRUE,
      caption = "Percentage change in the odds of participating if the response burden score increases by 100 points",
      label = "pc_odds",
      position = "h!") %>%
  kableExtra::kable_styling(font_size = 9) %>%
  kableExtra::footnote(general = "\\\\textit{RxI} = Recruited, with incentives, \\\\textit{N} negates.",
                       footnote_as_chunk = TRUE,
                       general_title = "",
                       escape = FALSE)
@

<<echo=FALSE, results='asis'>>=
tex
@

\begin{figure}
<<response curve, echo=FALSE, message=FALSE, fig.width=8, fig.height=3.8>>=
new_x <- seq(min(dat$x), max(dat$x), by = 0.01)
newdata <- data.frame(x = new_x)

m_ <- m[2:length(m)]  # drop pooled model
p <-
  map2(m_, names(m_), function(x, y) {
    p <- as.data.frame(predict(x, newdata = newdata, interval = "confidence"))
    p$name <- y
    p
  })
df <- reduce(p, rbind)

## backtransform (undo the logit)
df <-
  df %>%
  mutate(across(c(fit, lwr, upr), function(x) backtransform(x)),
         x = rep(1000 * newdata$x, 4))

survey_data <-
  dat %>%
  mutate(yb = backtransform(y),
         xb = x * 1000) %>%
  pivot_longer(all_of(cat_cols)) %>%
  filter(value == 1)

new_surveys <- survey_data[67:nrow(survey_data), ]

p <-
  df %>%
  ggplot(aes(x = x, group = name, shape = name)) +
  geom_point(aes(x = xb, y = yb, col = name), data = survey_data) +
  geom_point(aes(x = xb, y = yb, col = name), data = new_surveys, size = 5, show.legend = FALSE) +
  geom_line(aes(y = fit, col = name), linewidth = 1.5) +
  geom_ribbon(aes(ymin = lwr, ymax = upr, col = name), fill = "grey", linetype = "dashed", alpha = 0.2, show.legend = FALSE) +
  scale_shape_manual(values = c(15, 16, 17, 18)) +
  scale_fill_manual(values = my_colors) +
  scale_color_manual(values = my_colors) +
  labs(x = "Response burden", y = "Response rate [%]",
       col = "Recruitment, incentive", linetype = "Recruitment, incentive",
       shape = "Recruitment, incentive") +
  ggtitle("All categories") +
  my_theme() +
  theme(legend.position = "inside",
        legend.position.inside = c(1, 1),
        legend.justification = c(1.05, 1.1),
        legend.title = element_text(size = rel(0.7)),
        legend.text = element_text(size = rel(0.6)),
        legend.key.size = unit(0.3, "cm"),
        axis.title = element_text(size = rel(1.1)),
        plot.title = element_text(size = rel(0.9))) +
  expander() +
  Heimisc::add_grid(linetype = "solid", linewidth = 0.2) +
  guides(shape = guide_legend(override.aes = list(linewidth = 1, size = 3), ncol = 2))

## plot by category
m_last_ <- m_last[2:length(m_last)]
p_last <-
  map2(m_last_, names(m_last_), function(x, y) {
    p <- as.data.frame(predict(x, newdata = newdata, interval = "confidence"))
    p$name <- y
    p
  })
df_last <- reduce(p_last, rbind)

df_last <-
  df_last %>%
  mutate(across(c(fit, lwr, upr), function(x) backtransform(x)),
         x = rep(1000 * newdata$x, 3))

geom_response <- function(mapping = NULL, data = NULL, col, shade = "grey", lw = 1, alpha = 0.2) {
  list(
    geom_line(aes(x = x, y = fit), col = col, data = data, linewidth = lw),
    geom_ribbon(aes(x = x, ymin = lwr, ymax = upr), data = data, col = col, fill = shade, linetype = "dashed", alpha = alpha, show.legend = FALSE)
  )
}

plot_by_category <- function(df1, df2, survey_data, cat, col, shape, ylim = c(0, 100)) {
  e_yy <- filter(df1, name == cat)
  e_yy_l <- filter(df2, name == cat)
  sur_dat <- filter(survey_data, name == cat)
  sur_dat_n <- filter(survey_data[67:nrow(survey_data), ], name == cat)

  caption <- paste0("N = ", nrow(sur_dat), " (", nrow(sur_dat_n), " new)")

  ggplot() +
    ylim(ylim[1], ylim[2]) +
    geom_point(aes(x = xb, y = yb), data = sur_dat, size = 1, shape = shape, col = col) +
    geom_point(aes(x = xb, y = yb), data = sur_dat_n, size = 3, shape = shape, col = col, show.legend = FALSE) +
    geom_response(data = e_yy_l, col = "deeppink", lw = 1.5) +
    geom_response(data = e_yy, col = col) +
    labs(x = "Response burden", y = "RR [%]") +
    ggtitle(cat) +
    my_theme() +
    theme(plot.title = element_text(size = rel(0.9))) +
    expander() +
    Heimisc::add_grid(linetype = "solid", linewidth = 0.2) +
    annotate("text", x = max(e_yy$x), y = 100, label = caption, hjust = 1.2, vjust = 1.2)
}

p_yy <- plot_by_category(df, df_last, survey_data, cat = "RxI", shape = 18, col = "darkgrey")
p_nn <- plot_by_category(df, df_last, survey_data, cat = "NRxNI", shape = 15, col = "aquamarine3")
p_yn <- plot_by_category(df, df_last, survey_data, cat = "RxNI", shape = 17, col = "blue4")
p_ny <- plot_by_category(df, df_last, survey_data, cat = "NRxI", shape = 16, col = "darkorange")

(p | (p_yy / p_ny) | (p_yn / p_nn)) + patchwork::plot_layout(widths = c(2.5, 1, 1))
@
\caption{Response rate curves (response rates as a function of the response burden). The left-hand panel compares the curves for each \textit{recruitment x incentive} category based on the four separately estimated models (\textit{RxI} stands for recruited, with incentives, \textit{N} negates). The right-hand (smaller) panels compare the response rate curves to the ones based on the data of the previous publication (pink lines). New data points (since the last publication) are enlarged.}
\label{fig:response_curves}
\end{figure}

The back-transformed relationship between response burden and response rates (response rate curve) is visualized in \cref{fig:response_curves}, along their confidence intervals (i.e., the shaded area reflects the uncertainty of the curve estimates and is not a prediction interval). Recruitment shifts the curve, while incentives flatten it. Notably, the domain above a response burden score of 2`000 is sparsely populated, and the few observations potentially strongly influence the curve's shape (however, according to \textit{Cook's distance} no influential outliers are present in our data). The results indicate that surveys beyond 2`000 points appear overly burdensome for respondents, sustaining high response rates only through recruitment efforts combined with incentive payments, intensive care of the respondents and general interest of the respondents in the topic of these intense studies.

Generally, the 14 new data points do not dramatically change the overall shape of the curves (\cref{fig:response_curves}, RHS), but the curves are slightly steeper as explained based on the parameter estimates. \textit{RxI} is almost identical (only two new data points were added). For \textit{NRxNI} the confidence bounds increased because two of the five added surveys have unprecedented high response rates. For the category \textit{RxNI} the function has gained support for higher response burdens which substantially steepened the curve and reduced its uncertainty. In particular, we now have higher confidence that the curve quickly joins the other response curves on the domain above 1`500 response burden points. I.e., recruitment without incentive payments only matters for surveys with low response burden (but can make a big difference there).

Similar to \citet{schmid2019predicting}, we can add a linear time-trend with the year 2004 (when the survey scoring effort started) serving as the base. The following code shows the trivial addition of the time-trend to the pooled model.

<<results='hide'>>=
dat$year <- dat$year - 2004

fit_t <- fit_t <- lm(y ~ 0 + x + RxI + RxNI + NRxI + NRxNI + year,
                     data = dat, weights = weight)

mt <- add_clustered(fit_t, cluster = dat$survey_id, type = "CR2")
@

We repeat the steps for the individual categories and synthesise the results in a table (\cref{tab:time_trend}). In contrast to \citet{schmid2019predicting} we do not find a negative time-trend and therefore do not support the hypothesis of a general fatigue and less willingness to participate in our surveys.

<<echo=FALSE, results='hide'>>=
estimator <- function(dat, subset) {
  dat_ <- subset(dat, subset = subset)
  fit <- lm(formula = y ~ x + year,
            data = dat_, weights = weight)
  m <- add_clustered(fit, cluster = dat_$survey_id, type = "CR2")
  m
}

rename_coefs <- function(m_list) {
  m_list_ <-
    map(m_list, function(x) {
      if (length(x$coefficients) == 3) {
        names(x$coefficients) <- c("Intercept", "Response burden", "Time-trend")
      } else {
        names(x$coefficients)[c(1, 6)] <- c("Response burden", "Time-trend")
      }
      x
    })
  return(m_list_)
}

mt2 <- estimator(dat, subset = (dat$RxI == 1))
mt3 <- estimator(dat, subset = (dat$RxNI == 1))
mt4 <- estimator(dat, subset = (dat$NRxI == 1))
mt5 <- estimator(dat, subset = (dat$NRxNI == 1))

m_time <- list(Pooled = mt,
               `RxI` = mt2,
               `RxNI`= mt3,
               `NRxI` = mt4,
               `NRxNI` = mt5)

m_time <- rename_coefs(m_time)  # helper to rename coefs for output

m_both <- append(m, m_time)

tex <- texreg::texreg(m_both,
                      booktabs = TRUE,
                      use.packages = FALSE,
                      caption.above = TRUE,
                      custom.header = list("No time-trend" = 1:5, "With time-trend" = 6:10),
                      caption = "Logistic regression results: Adding a linear time-trend",
                      label = "tab:time_trend",
                      custom.note = "%stars. \\textit{RxI} = Recruited, with incentives, \\textit{N} negates.",
                      scalebox = 0.72,
                      float.pos = "h!")
@

<<echo=FALSE, results='asis'>>=
tex
@


%%%%%%%%%%%%%%%%%%%%
% ACKNOWLEDGEMENTS
%%%%%%%%%%%%%%%%%%%%
\section{Acknowledgements}

We would like to thank all the students scoring the survey instruments and contributing to the data underlying this analysis.
